{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3415942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "import pickle\n",
    "import random\n",
    "import scipy\n",
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import GPy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from Kernel import MixtureViaSumAndProduct, CategoryOverlapKernel\n",
    "from InitialData_Gen import initialize\n",
    "from AcquisitionFunctions import EI, PI, UCB, AcquisitionOnSubspace\n",
    "# from SamplingCategorical import compute_prob_dist_and_draw_hts\n",
    "from UpdateCategoricalWeight import compute_reward_for_all_cat_variable, update_weights_for_all_cat_var\n",
    "from optimization import sample_then_minimize\n",
    "\n",
    "from AskTell import ask_tell\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from typing import Union, Tuple\n",
    "from paramz.transformations import Logexp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c1563",
   "metadata": {},
   "source": [
    "1. C - List of number of categroies corresponding to each categorical variable\n",
    "2. Nc - Number of categorical variables\n",
    "3. Nx - Continuous variables\n",
    "4. h - categorical\n",
    "5. x - continuous\n",
    "6. z - [h, x]\n",
    "\n",
    "7. nDim - Nc + Nx\n",
    "8. bounds - Lower and Upper bounds of both Catergorical variables and continuous variables\n",
    "\n",
    "9. n_iter - Number of iterations to run the algorithm\n",
    "10. initN - Number of intial data points\n",
    "11. batch_size (b) - Number of experiments to be generated in each iteration\n",
    "\n",
    "12. acq_type - Acquisition Type ('EI', 'LCB', 'ThompsonSampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7e7ce",
   "metadata": {},
   "source": [
    "### 1. Load Model background from the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150815bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "myString = sys.path[0]\n",
    "split_list = myString.split(\"/\")\n",
    "root = ''\n",
    "for l in split_list[1:-2]:\n",
    "    root = root +'/'+ l\n",
    "    \n",
    "main_file_path = root + '/HSA_TL/'\n",
    "carbon_source_fiepath = root + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_solid = pd.read_excel(carbon_source_fiepath + 'CarbonSourceInfo.xlsx', 'Stocks_solid')\n",
    "Stock_liquid = pd.read_excel(carbon_source_fiepath + 'CarbonSourceInfo.xlsx', 'Stocks_liquid')\n",
    "\n",
    "Carbon_Names = Stock_solid['Carbon Source'].values.tolist()\n",
    "Carbon_Names.append(Stock_liquid['Carbon Source'][1])\n",
    "Carbon_Names.append(Stock_liquid['Carbon Source'][2])\n",
    "\n",
    "Carbon_Ub = [50]*17 #[g/L]\n",
    "Carbon_Ub.append(10) # Glycerol [mL/L]\n",
    "Carbon_Ub.append(50) #Ethanol [mL/L]\n",
    "\n",
    "OG_Gly_Ub = 100 #[mL/L]\n",
    "Met_Ub = 100 #[mL/L]\n",
    "\n",
    "Glu_Ub = 50 #mM\n",
    "Tween_Ub = 1# 1%\n",
    "pH_Ub = 6.5# \n",
    "\n",
    "Stock_Conc = Stock_solid['g/mL'].values.tolist()\n",
    "Stock_Conc.append(Stock_liquid['mL/mL'][1].tolist())\n",
    "Stock_Conc.append(Stock_liquid['mL/mL'][2].tolist())\n",
    "\n",
    "OG_Stock_Conc = Stock_liquid['mL/mL'][0].tolist()\n",
    "\n",
    "Glu_Stock_Conc = 250 #mM\n",
    "Tween_Stock_Conc = 50# %\n",
    "pH_Stock_Conc = 1# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b59acf",
   "metadata": {},
   "source": [
    "### 2. Read Experimental condition and results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf17845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a titer quantification file and create the result array\n",
    "alt_path = root\n",
    "AllData = pd.read_csv(alt_path +'AllMolecule/HSA_CoCaBO_Prod_AllData.csv')\n",
    "result = AllData['SP'].values.reshape(-1,1)\n",
    "\n",
    "data = AllData.iloc[:,1:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d4bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Carbon_mL = []\n",
    "OG_Gly_mL = []\n",
    "Met_mL = []\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    if int(data[i,0]) !=19:\n",
    "        temp_factor = Carbon_Ub[int(data[i,0])]\n",
    "    else:\n",
    "        temp_factor = Carbon_Ub[0]\n",
    "    temp = data[i,1]/(temp_factor)\n",
    "    Carbon_mL.append(temp)\n",
    "    OG_Gly_mL.append(data[i,2]/OG_Gly_Ub * 1000/100)\n",
    "    Met_mL.append(data[i,3]/Met_Ub*1000/100)\n",
    "    \n",
    "data_sc = np.concatenate((data[:,0:1],np.array(Carbon_mL).reshape(-1,1),\n",
    "                          np.array(OG_Gly_mL).reshape(-1,1), np.array(Met_mL).reshape(-1,1)), axis = 1)\n",
    "\n",
    "data_sc = np.concatenate((data_sc, \n",
    "                          1e-5 * np.ones((AllData.shape[0],4)), \n",
    "                          0.999 * np.ones((AllData.shape[0],1))), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0823c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a titer quantification file and create the result array\n",
    "N_round = 1\n",
    "Design = {}\n",
    "Result_df = {}\n",
    "for nr in range(N_round):\n",
    "    file_name = main_file_path + 'Codes/Round' + str(nr) + '/Reconstructed_Round' + str(nr) + '.csv'\n",
    "    Design[nr] = pd.read_csv(file_name)\n",
    "    Column_Names = pd.read_csv(file_name).columns\n",
    "    file_name_res = main_file_path + 'Exp/Round' + str(nr) + '/Round' + str(nr) + '_Result_Summary_final.csv'\n",
    "    Result_df[nr] = pd.read_csv(file_name_res)\n",
    "    fac = int(Result_df[nr].shape[0]/Design[nr].shape[0])\n",
    "    temp = np.repeat(Design[nr].iloc[:,1:].values,fac, axis = 0)\n",
    "#     print(temp)\n",
    "# #     for j in range(Design[nr].shape[0]):\n",
    "#         temp = np.repeat(Design[nr].iloc[:,1:].values,2, axis = 0)\n",
    "    data_sc = np.concatenate((data_sc, temp), axis = 0)\n",
    "        \n",
    "    result = np.concatenate((result, Result_df[nr]['Specific Productivity'].iloc[:-1,].values.reshape(-1,1)), axis = 0)\n",
    "    \n",
    "mu_y = np.mean(result, 0)\n",
    "std_y = np.std(result, 0)\n",
    "\n",
    "mu_x = np.mean(data_sc, 0)\n",
    "std_x = np.std(data_sc, 0)\n",
    "\n",
    "data_norm = (data_sc - mu_x)/std_x\n",
    "data_norm[:,0] = data_sc[:,0]\n",
    "\n",
    "result_norm = (result - mu_y)/std_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f99372",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nc = 1\n",
    "C_list = [19] #\n",
    "\n",
    "assert Nc == len(C_list)\n",
    "\n",
    "Nx = 8 #3+5\n",
    "nDim = Nc + Nx\n",
    "Niter = 1\n",
    "batch_size = 10\n",
    "initN = data.shape[0]\n",
    "\n",
    "bounds = [{'name': 'Carbon_Type', 'type': 'categorical', 'domain': np.arange(0, 19)}, #Carbon Source type\n",
    "          {'name': 'Conc_Carbon', 'type': 'continuous', 'domain': (0, 1)},\n",
    "            {'name': 'Gly_OG', 'type': 'continuous', 'domain': (0, 1)},\n",
    "            {'name': 'Met_Prod', 'type': 'continuous', 'domain': (0, 1)},\n",
    "         {'name': 'Glu_OG', 'type': 'continuous', 'domain': (0, 1)},\n",
    "         {'name': 'Tween_OG', 'type': 'continuous', 'domain': (0, 1)},\n",
    "         {'name': 'Glu_Prod', 'type': 'continuous', 'domain': (0, 1)},\n",
    "         {'name': 'Tween_Prod', 'type': 'continuous', 'domain': (0, 1)},\n",
    "         {'name': 'pH', 'type': 'continuous', 'domain': (5.75/6.5, 6.5/6.5)}]\n",
    "\n",
    "\n",
    "# load data from pkl file\n",
    "background_file = main_file_path +  \"Codes/Round0/5_ModelBackground_HSA_Prod.pkl\"\n",
    "with open(background_file, \"rb\") as fp:\n",
    "    ModelBackground_0 = pickle.load(fp)\n",
    "    \n",
    "ModelBackground_0['data_param']['Meas_Noise'] = 0.034\n",
    "ModelBackground_0['data_param']['tarde_off'] = 3\n",
    "ModelBackground_0['data_param']['Nx'] = Nx\n",
    "ModelBackground_0['data_param']['nDim'] = nDim\n",
    "ModelBackground_0['data_param']['bounds'] = bounds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelBackground_0['data_param']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727be563",
   "metadata": {},
   "source": [
    "### 3. First iteration to ask the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5574311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update Weights from the CoCaBO_prod with results from run 0 (Only done here, since round 0 was generated with old code bundle\n",
    "#New code bundle already has this incorporated). From next round, this can be skipped\n",
    "batch_size = 11\n",
    "ht_next_list_array = np.zeros((batch_size,1))\n",
    "ht_next_list_array[:,0:1] = np.atleast_2d(np.array(ModelBackground_0['Categorical_dist_param']['ht_batch_list']))\n",
    "ht_list_rewards = compute_reward_for_all_cat_variable(ht_next_list_array, C_list,\n",
    "                                                      data,result_norm, batch_size) # np.divide(result,np.max(result))\n",
    "\n",
    "Wc_list = update_weights_for_all_cat_var(C_list, \n",
    "                ht_list_rewards, ht_next_list_array ,\n",
    "                 ModelBackground_0['Categorical_dist_param']['Wc_list'], ModelBackground_0['gamma_list'],\n",
    "                ModelBackground_0['Categorical_dist_param']['probabilityDistribution_list'],\n",
    "                batch_size, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "z_next, Categorical_dist_param, gp_actual = ask_tell(data_sc, result, ModelBackground_0['data_param'], \n",
    "                                          'RBF', 'constant_liar',  batch_size, \n",
    "                                           Wc_list,  \n",
    "                                          ModelBackground_0['gamma_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21529ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(z_next).to_csv('./Round1/1_ExperimentalDesign.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a12230",
   "metadata": {},
   "source": [
    "### 4. Store the Model background parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420dc5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelBackground_1 = {}\n",
    "ModelBackground_1 = {'gamma_list': ModelBackground_0['gamma_list'],  'budget': ModelBackground_0['budget'],\n",
    "                 'bestUpperBoundEstimate': ModelBackground_0['bestUpperBoundEstimate'], \n",
    "                    'data_param': ModelBackground_0['data_param'], \n",
    "                   'Categorical_dist_param': Categorical_dist_param}\n",
    "\n",
    "import pickle\n",
    "with open('./Round1/1_ModelBackground.pkl', 'wb') as output:\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    pickle.dump(ModelBackground_1, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dd8cc4",
   "metadata": {},
   "source": [
    "### 5. Conversion to actual experimental execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_Carbon = []\n",
    "Carbon_mL = []\n",
    "OG_Gly_mL = []\n",
    "Met_mL = []\n",
    "Glu_OG_mL = []\n",
    "Tween_OG_mL = []\n",
    "Glu_Prod_mL = []\n",
    "Tween_Prod_mL = []\n",
    "pH_mL = []\n",
    "\n",
    "for i in range(batch_size):\n",
    "    Selected_Carbon.append(Carbon_Names[int(z_next[i,0])])\n",
    "    temp_factor = Carbon_Ub[int(z_next[i,0])]/ Stock_Conc[int(z_next[i,0])]\n",
    "    temp = z_next[i,1] * temp_factor * 3\n",
    "    # [g/L]/[g/mL] * [mL] --> g * mL * mL/[L * g] --> 10^-6 L --> uL \n",
    "    Carbon_mL.append(temp)\n",
    "    # [mL]*[mL/L] --> 10^-6 L --> 1 uL \n",
    "    OG_Gly_mL.append(z_next[i,2] * OG_Gly_Ub * 3/OG_Stock_Conc)\n",
    "    Met_mL.append(z_next[i,3] * Met_Ub * 3)\n",
    "    \n",
    "    Glu_OG_mL.append(z_next[i,4] * Glu_Ub * 3 * 1000/Glu_Stock_Conc) # uL\n",
    "    Tween_OG_mL.append(z_next[i,5] * Tween_Ub * 3 * 1000/Tween_Stock_Conc) #uL\n",
    "    Glu_Prod_mL.append(z_next[i,6] * Glu_Ub * 3 * 1000/Glu_Stock_Conc) # uL\n",
    "    Tween_Prod_mL.append(z_next[i,7] * Tween_Ub * 3 * 1000/Tween_Stock_Conc) #uL\n",
    "    pH_mL.append(z_next[i,8] * pH_Ub ) #* 3/pH_Stock_Conc\n",
    "    \n",
    "\n",
    "\n",
    "Experiment_1_3mL = {'Carbon_Type': Selected_Carbon,\n",
    "               'Conc_Carbon [uL]': Carbon_mL,\n",
    "               'Gly_OG [uL]': OG_Gly_mL,\n",
    "               'Met_Prod [uL]': Met_mL,\n",
    "                'Glu_OG [uL]' :Glu_OG_mL,\n",
    "                'Tween_OG [uL]':Tween_OG_mL,\n",
    "                'Glu_Prod [uL]': Glu_Prod_mL ,\n",
    "                'Tween_Prod [uL]': Tween_Prod_mL ,  \n",
    "                  'pH': pH_mL }\n",
    "\n",
    "pd.DataFrame(Experiment_1_3mL).to_csv('./Round1/1_ExperimentPlan_mLValue_3mL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d1c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_sc[:,0], data_sc[:,1])\n",
    "plt.scatter(z_next[:,0],z_next[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c3a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_sc[:,2], data_sc[:,3])\n",
    "plt.scatter(z_next[:,2],z_next[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_sc[:,4], data_sc[:,5])\n",
    "plt.scatter(z_next[:,4],z_next[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_sc[:,5], data_sc[:,6])\n",
    "plt.scatter(z_next[:,5],z_next[:,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56617f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_sc[:,7], data_sc[:,8])\n",
    "plt.scatter(z_next[:,7],z_next[:,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea3feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Experiment_1_3mL).to_csv('./Round1/Actual_Round1_3mL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33329bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
