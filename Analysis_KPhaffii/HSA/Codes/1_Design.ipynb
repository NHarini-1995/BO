{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3415942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "import pickle\n",
    "import random\n",
    "import scipy\n",
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import GPy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from Kernel import MixtureViaSumAndProduct, CategoryOverlapKernel\n",
    "from InitialData_Gen import initialize\n",
    "from AcquisitionFunctions import EI, PI, UCB, AcquisitionOnSubspace\n",
    "# from SamplingCategorical import compute_prob_dist_and_draw_hts\n",
    "from UpdateCategoricalWeight import compute_reward_for_all_cat_variable, update_weights_for_all_cat_var\n",
    "from optimization import sample_then_minimize\n",
    "\n",
    "from AskTell import ask_tell\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from typing import Union, Tuple\n",
    "from paramz.transformations import Logexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cee8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "myString = sys.path[0]\n",
    "split_list = myString.split(\"/\")\n",
    "root = ''\n",
    "for l in split_list[1:-2]:\n",
    "    root = root +'/'+ l\n",
    "    \n",
    "main_file_path = root + '/HSA/'\n",
    "carbon_source_fiepath = root + '/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c1563",
   "metadata": {},
   "source": [
    "1. C - List of number of categroies corresponding to each categorical variable\n",
    "2. Nc - Number of categorical variables\n",
    "3. Nx - Continuous variables\n",
    "4. h - categorical\n",
    "5. x - continuous\n",
    "6. z - [h, x]\n",
    "\n",
    "7. nDim - Nc + Nx\n",
    "8. bounds - Lower and Upper bounds of both Catergorical variables and continuous variables\n",
    "\n",
    "9. n_iter - Number of iterations to run the algorithm\n",
    "10. initN - Number of intial data points\n",
    "11. batch_size (b) - Number of experiments to be generated in each iteration\n",
    "\n",
    "12. acq_type - Acquisition Type ('EI', 'LCB', 'ThompsonSampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7e7ce",
   "metadata": {},
   "source": [
    "### 1. Load Model background from the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f93cfb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from pkl file\n",
    "background_file = main_file_path +  \"Codes/Round0/0_ModelBackground.pkl\"\n",
    "with open(background_file, \"rb\") as fp:\n",
    "    ModelBackground_0 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b59acf",
   "metadata": {},
   "source": [
    "### 2. Read Experimental condition and results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf17845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a titer quantification file and create the result array\n",
    "N_round = 1\n",
    "Design = {}\n",
    "Result_df = {}\n",
    "for nr in range(N_round):\n",
    "    file_name = main_file_path + 'Codes/Round' + str(nr) + '/Reconstructed_Round' + str(nr) + '.csv'\n",
    "    Design[nr] = pd.read_csv(file_name)\n",
    "    Column_Names = pd.read_csv(file_name).columns\n",
    "    file_name_res = main_file_path + 'Exp/Round' + str(nr) + '/Round' + str(nr) + '_Result_Summary.csv'\n",
    "    Result_df[nr] = pd.read_csv(file_name_res)\n",
    "    \n",
    "    if nr == 0:\n",
    "        data = Design[nr].iloc[:,1:].values\n",
    "        result = Result_df[nr]['Specific Productivity'].iloc[:-1,].values.reshape(-1,1)\n",
    "    else:\n",
    "        data = np.concatenate((data, Design[nr].iloc[:,1:].values), axis = 0)\n",
    "        result = np.concatenate((result, Result_df[nr]['Specific Productivity'].iloc[:-1,].values.reshape(-1,1)), axis = 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e26c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelBackground_0['data_param']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727be563",
   "metadata": {},
   "source": [
    "### 3. First iteration to ask the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe0f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 11\n",
    "\n",
    "random.seed(37)\n",
    "\n",
    "z_next, Categorical_dist_param = ask_tell(data[0:23,:], result[0:23,:], ModelBackground_0['data_param'], \n",
    "                                          'Matern52', 'thompson_sampling',  batch_size, \n",
    "                                           ModelBackground_0['Wc_list'],  ModelBackground_0['gamma_list'])\n",
    "# print(data)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d1c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.scatter(z_next[:,0],z_next[:,1])\n",
    "plt.xticks(np.arange(0,19,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c3a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data[:,2], data[:,3])\n",
    "plt.scatter(z_next[:,2],z_next[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21529ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(z_next).to_csv('./Round1/1_ExperimentalDesign.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a12230",
   "metadata": {},
   "source": [
    "### 4. Store the Model background parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420dc5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelBackground_1 = {}\n",
    "ModelBackground_1 = {'gamma_list': ModelBackground_0['gamma_list'],  'budget': ModelBackground_0['budget'],\n",
    "                 'bestUpperBoundEstimate': ModelBackground_0['bestUpperBoundEstimate'], \n",
    "                     'Wc_list_init': ModelBackground_0['Wc_list_init'],\n",
    "                   'Wc_list': ModelBackground_0['Wc_list'], 'data_param': ModelBackground_0['data_param'], \n",
    "                   'Categorical_dist_param': Categorical_dist_param}\n",
    "\n",
    "import pickle\n",
    "with open('./Round1/1_ModelBackground.pkl', 'wb') as output:\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    pickle.dump(ModelBackground_1, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dd8cc4",
   "metadata": {},
   "source": [
    "### 5. Conversion to actual experimental execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_solid = pd.read_excel(carbon_source_fiepath  + 'CarbonSourceInfo.xlsx', 'Stocks_solid')\n",
    "Stock_liquid = pd.read_excel(carbon_source_fiepath + 'CarbonSourceInfo.xlsx', 'Stocks_liquid')\n",
    "\n",
    "Carbon_Names = Stock_solid['Carbon Source'].values.tolist()\n",
    "Carbon_Names.append(Stock_liquid['Carbon Source'][1])\n",
    "Carbon_Names.append(Stock_liquid['Carbon Source'][2])\n",
    "\n",
    "Carbon_Ub = [50]*17 #[g/L]\n",
    "Carbon_Ub.append(10) # Glycerol [mL/L]\n",
    "Carbon_Ub.append(50) #Ethanol [mL/L]\n",
    "\n",
    "OG_Gly_Ub = 100 #[mL/L]\n",
    "Met_Ub = 100 #[mL/L]\n",
    "\n",
    "Stock_Conc = Stock_solid['g/mL'].values.tolist()\n",
    "Stock_Conc.append(Stock_liquid['mL/mL'][1].tolist())\n",
    "Stock_Conc.append(Stock_liquid['mL/mL'][2].tolist())\n",
    "\n",
    "OG_Stock_Conc = Stock_liquid['mL/mL'][0].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_Carbon = []\n",
    "Carbon_mL = []\n",
    "OG_Gly_mL = []\n",
    "Met_mL = []\n",
    "\n",
    "\n",
    "for i in range(batch_size):\n",
    "    Selected_Carbon.append(Carbon_Names[int(z_next[i,0])])\n",
    "    temp_factor = Carbon_Ub[int(z_next[i,0])]/ Stock_Conc[int(z_next[i,0])]\n",
    "    temp = z_next[i,1] * temp_factor * 3\n",
    "    Carbon_mL.append(temp)\n",
    "    OG_Gly_mL.append(z_next[i,2] * OG_Gly_Ub * 3/OG_Stock_Conc)\n",
    "    Met_mL.append(z_next[i,3] * Met_Ub * 3)\n",
    "    \n",
    "\n",
    "\n",
    "Experiment_1_3mL = {'Carbon_Type': Selected_Carbon,\n",
    "               'Conc_Carbon [uL]': Carbon_mL,\n",
    "               'Gly_OG [uL]': OG_Gly_mL,\n",
    "               'Met_Prod [uL]': Met_mL}\n",
    "\n",
    "pd.DataFrame(Experiment_1_3mL).to_csv('./Round1/1_ExperimentPlan_mLValue_3mL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e32f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
